{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_transform as tft\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as cls\n",
    "import os\n",
    "import pyts.image as pyti\n",
    "import pyts.approximation as pyta\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define the model that we will use for the prediction. \n",
    "\n",
    "The model used in the paper is a slight variation of the standard CNN model from TensorFlow, which was used to classify images from Cifar-10 dataset.\n",
    "\n",
    "In our case it will predict the wear class of the cutter from the 4 possibilities: \"Break-in\", \"Steady\", \"Severe\" and \"Failure\".\n",
    "\n",
    "Our inputs are 3-layer RGB images, transformed via Gramian Angular Summation Field and smoothed out with PAA such that the shape of the input image is 256x256. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 512, 512, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 127, 127, 64)      12352     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 42, 42, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 64)          262208    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               196800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 772       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 472,132\n",
      "Trainable params: 472,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (512, 512, 3) # 3-channel 512x512 images\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=input_shape),\n",
    "    layers.Conv2D(64, (8, 8), strides=4, activation='relu'),\n",
    "    layers.MaxPooling2D((3, 3)),\n",
    "    layers.Conv2D(64, (8, 8), strides=4, activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(192),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the model we can create a pre-processing function which will take the input and turn it into images. \n",
    "\n",
    "In fact we can copy function `get_gasf` from previous notebook and apply few changes to it, and voila.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DIR='../../Datasets/PHM2010Challenge/c1/c1/'\n",
    "IMAGE_DIR=\"Images/\" # Save to current folder\n",
    "LABELS=['Break_in', 'Steady_state', 'Severe', 'Failure']\n",
    "\n",
    "def rescale(x, low=0, high=1):\n",
    "    return (high - low) * (x - np.min(x)) / (np.max(x) - np.min(x)) + low\n",
    "\n",
    "def filename_to_class(filename):\n",
    "    # Create the label\n",
    "    file_string = os.path.basename(filename)\n",
    "    (_, _, cut_event, _) = re.split(r\"_|\\.\", file_string)\n",
    "    cut_event = int(cut_event)\n",
    "    if cut_event < 50:\n",
    "        label = LABELS[0]\n",
    "    elif cut_event < 175:\n",
    "        label = LABELS[1]\n",
    "    elif cut_event < 250:\n",
    "        label = LABELS[2]\n",
    "    else:\n",
    "        label = LABELS[3]\n",
    "    return label\n",
    "\n",
    "def get_gasf(cutter_sample):\n",
    "    # Casting the time-domain data to RGB layers --- assume only appropriate columns are included\n",
    "    cutter_acos = rescale(cutter_sample, low=-1, high=1)\n",
    "    cutter_acos = np.arccos(cutter_acos)\n",
    "    cutter_acos = np.asarray(cutter_acos).transpose()\n",
    "    paa = pyta.PiecewiseAggregateApproximation(window_size=4)\n",
    "    fcutter_paa = paa.transform(cutter_acos) # Piecewise Aggregate Approximation applied to the time-domain data\n",
    "    nelem = fcutter_paa.shape[1]\n",
    "    gasf = pyti.GramianAngularField(image_size=nelem, method='summation') # Grammar Angular Summation Field\n",
    "    fcutter_gasf = gasf.transform(fcutter_paa)\n",
    "    image = fcutter_gasf.reshape((512, 512, 3))\n",
    "    image = rescale(image, low=0, high=1)\n",
    "    return image\n",
    "\n",
    "def dataset_slices(filename, num_slices=3):\n",
    "    cutter_sample = pd.read_csv(filename, header=None,\n",
    "                    names=['Fx', 'Fy', 'Fz', 'Vx', 'Vy', 'Vz', 'aerms'],\n",
    "                    usecols=['Fx', 'Fy', 'Fz'])\n",
    "    nrow, ncol = cutter_sample.shape\n",
    "    nelem = 2048\n",
    "    start_idx = np.random.choice(nrow-nelem, num_slices)\n",
    "    cutter_array = np.asarray(cutter_sample)\n",
    "    dataset_sliced = np.zeros((num_slices, nelem, ncol))\n",
    "    for i, _idx in enumerate(start_idx):\n",
    "        dataset_sliced[i] = cutter_array[_idx:(_idx+nelem)]\n",
    "    return start_idx, dataset_sliced\n",
    "\n",
    "def populate_image_files(filename, num_files=3, image_dir=IMAGE_DIR):\n",
    "    # From given file `filename` create `num_files` GASF images with image and label\n",
    "    basename = re.split( r\"\\.\", os.path.basename(filename))[0]\n",
    "    start_idx, data_slices = dataset_slices(filename, num_slices=num_files)\n",
    "    label = filename_to_class(filename)\n",
    "\n",
    "    # Create the appropriate folder if non-existent\n",
    "    class_dir = os.path.join(image_dir, label)\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.mkdir(class_dir)\n",
    "    \n",
    "    for i in range(num_files):\n",
    "        gasf_image = get_gasf(data_slices[i])\n",
    "        output_filename = os.path.join(class_dir, \"%s-%s-%.3d.jpeg\" % (label, basename, i))\n",
    "        tf.keras.utils.save_img(output_filename, gasf_image)\n",
    "    return start_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it would be probably better to load directly the CSV files and preprocess them in the memory (not to create additional files on the disk), for simplicity we will create additional folder with the GASF images as RGB images, which can then be easily loaded to TensorFlow.\n",
    "\n",
    "From each file we will take 3 continuous samples of size 2048 from different parts of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving image: c_1_117.csv\n",
      "------------ 0/315\n",
      "Saving image: c_1_065.csv\n",
      "------------ 50/315\n",
      "Saving image: c_1_215.csv\n",
      "------------ 100/315\n",
      "Saving image: c_1_223.csv\n",
      "------------ 150/315\n",
      "Saving image: c_1_146.csv\n",
      "------------ 200/315\n",
      "Saving image: c_1_294.csv\n",
      "------------ 250/315\n",
      "Saving image: c_1_047.csv\n",
      "------------ 300/315\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(CSV_DIR)\n",
    "num_slices = 3\n",
    "\n",
    "file_indexes_dict = {}\n",
    "for i, filename in enumerate(filenames):\n",
    "    if i % 50 == 0:\n",
    "        print(\"Saving image: %s\" % filename)\n",
    "        print(\"------------ %d/%d\" % (i, len(filenames)))\n",
    "    \n",
    "    idx = populate_image_files(os.path.join(CSV_DIR, filename),\n",
    "                        num_files=num_slices, image_dir=IMAGE_DIR)\n",
    "    file_indexes_dict[filename] = idx\n",
    "\n",
    "print(\"Finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also save the `file_indexes_dict` to be able to get back to the indices in the original files. Since the numpy types are not json-serializable we will transform them to lists with Python types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_indexes_dict_list = {k: [int(x) for x in list(v)] for k, v in file_indexes_dict.items()}\n",
    "with open(\"Images.json\", \"w\") as json_file:\n",
    "    json.dump(file_indexes_dict_list, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it was not the most elegant solution, but it's fine, at least we have a dataset where we exactly know the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 945 files belonging to 4 classes.\n",
      "Using 662 files for training.\n",
      "Found 945 files belonging to 4 classes.\n",
      "Using 283 files for validation.\n"
     ]
    }
   ],
   "source": [
    "SEED=1234 # Using the same seed for both traning and validation datasets\n",
    "img_height, img_width = 512, 512\n",
    "VALIDATION_SPLIT = 0.3\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    seed=SEED,\n",
    "    image_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    labels='inferred',\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='training',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    seed=SEED,\n",
    "    image_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    labels='inferred',\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='validation',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    steps_per_execution=2)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict( history.history )\n",
    "history_df.plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
